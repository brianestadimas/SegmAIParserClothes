{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import Subset\n",
    "import shutil\n",
    "from codes.helpers import FocalLoss\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_name_to_load = \"final_model.pth\"\n",
    "\n",
    "batch_size = 1\n",
    "device = \"cuda\"\n",
    "logdir = \"logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Fashion_Data(Dataset):\n",
    "    def __init__(self, folder_train, augmentation=None):\n",
    "        self.folder_train = folder_train\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "        self.filenames = [f for f in os.listdir(folder_train) if os.path.isfile(os.path.join(folder_train, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name_train = os.path.join(self.folder_train, self.filenames[idx])\n",
    "\n",
    "        img_train = Image.open(img_name_train).convert('L')\n",
    "        img_train = self.transform(img_train)\n",
    "\n",
    "        return img_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "test_folder = \"logs/input/\"\n",
    "test_set = Fashion_Data(test_folder)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The diagram is provided to understand the architecture\n",
    "from architecture.segnet import SegNet\n",
    "\n",
    "generator = SegNet(in_channels=1, out_channels=1).to(device)\n",
    "generator = DataParallel(generator)\n",
    "generator.load_state_dict(torch.load(f'logs/{generator_name_to_load}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "# The code to make sure the model input and output are correct, we can test the first batch to fed into the network\n",
    "data = next(iter(test_dataloader))\n",
    "\n",
    "test_data = data\n",
    "output_test = generator(test_data.to(device))\n",
    "print(output_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  6.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# generator.eval()\n",
    "pbar = tqdm(test_dataloader)\n",
    "for idx, x in enumerate(pbar):\n",
    "    x = x.to(device, dtype=torch.float32)\n",
    "    output = generator(x)\n",
    "    for j, gen_image in enumerate(output):\n",
    "        save_image(gen_image, os.path.join(\"logs\", \"output\", f\"generated_{idx}_{j}.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
